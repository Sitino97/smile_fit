<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="utf-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>íƒ€ì›Œ ë””íœìŠ¤ ì¬í™œ ê²Œì„ | SMILE FIT</title>
    <link rel="shortcut icon" href="{{ url_for('static', filename='unity_game_files/TemplateData/favicon.ico') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='unity_game_files/TemplateData/style.css') }}">
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@500&family=SUIT:wght@400;600&display=swap" rel="stylesheet">
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        /* ... (ê¸°ì¡´ CSS - ë³€ê²½ ì—†ìŒ) ... */
        body { margin: 0; overflow: hidden; font-family: 'SUIT', sans-serif; text-align: center; background: radial-gradient(ellipse at center, #0f2027, #203a43, #2c5364); color: #00ffe1;}
        #unity-container{
            width: 960px;
            height: 600px;
            margin: auto;
        }
        #facial-recognition-modal {
            display: none;
            position: fixed;
            left: 0; top: 0; width: 100%; height: 100%;
            background-color: rgba(0,0,0,0.85);
            z-index: 1000;
            color: #00ffe1;
            align-items: center;
            justify-content: center;
            flex-direction: column;
            padding: 20px;
            box-sizing: border-box;
        }
        #facial-recognition-modal .modal-container {
            display: flex;
            justify-content: center;
            align-items: flex-start;
            gap: 20px;
            margin-top: 20px;
            flex-wrap: wrap;
        }
        #facial-recognition-modal img,
        #facial-recognition-modal video,
        #facial-recognition-modal canvas#emotion-guideCanvas {
            width: 300px;
            height: 225px;
            border: 2px solid #00ffe1;
            box-shadow: 0 0 10px #00ffe1;
            background-color: #000;
        }
        #facial-recognition-modal video#emotion-video {
            transform: scaleX(-1);
        }
        #facial-recognition-modal canvas#emotion-guideCanvas {
            position: absolute;
            top:0;
            left:0;
            pointer-events: none;
        }
        #facial-recognition-modal .emotion-display-text {
            font-size: 18px;
            margin-top: 10px;
            text-shadow: 0 0 5px #00ffe1;
        }
        #facial-recognition-modal button {
            margin-top: 15px;
            padding: 10px 20px;
            font-size: 16px;
            border: 2px solid #00ffe1;
            background: transparent;
            color: #00ffe1;
            border-radius: 10px;
            cursor: pointer;
            box-shadow: 0 0 10px #00ffe1;
            transition: all 0.3s ease;
        }
        #facial-recognition-modal button:hover {
            background-color: #00ffe133;
            box-shadow: 0 0 15px #00ffe1;
        }
        #facial-recognition-modal h3 {
            font-family: 'Orbitron', sans-serif;
            font-size: 20px;
            margin-bottom: 5px;
        }
        #facial-recognition-modal p {
            margin-top: 0;
            font-size: 16px;
            color: #fff;
        }
    </style>
</head>
<body>
    <div id="unity-container" class="unity-desktop">
        <canvas id="unity-canvas" width=960 height=600 tabindex="-1"></canvas>
        <div id="unity-loading-bar">
            <div id="unity-logo"></div>
            <div id="unity-progress-bar-empty">
                <div id="unity-progress-bar-full"></div>
            </div>
        </div>
        <div id="unity-warning"> </div>
        <div id="unity-footer">
            <div id="unity-logo-title-footer"></div>
            <div id="unity-fullscreen-button"></div>
            <div id="unity-build-title">towerdefense</div>
        </div>
    </div>

    <div id="facial-recognition-modal">
        <div id="emotion-mode-ui" style="display: none; text-align: center;">
            <h3>ê°ì • í‘œí˜„í•˜ê¸°</h3>
            <p>ì œì‹œëœ ê°ì •ì„ í‘œì •ìœ¼ë¡œ í‘œí˜„í•´ë³´ì„¸ìš”!</p>
            <div class="modal-container">
                <div>
                    <img id="emotion-referenceImg" src="" alt="ê¸°ì¤€ ê°ì • ì´ë¯¸ì§€">
                    <div id="emotion-refEmotionDisplay" class="emotion-display-text">ê¸°ì¤€ ê°ì •: -</div>
                </div>
                <div style="position: relative;">
                    <video id="emotion-video" autoplay muted playsinline></video>
                    <canvas id="emotion-guideCanvas" width="300" height="225"></canvas>
                    <div id="emotion-userEmotionDisplay" class="emotion-display-text">ë‹¹ì‹  ê°ì •: -</div>
                </div>
            </div>
            <button id="emotion-captureBtn">ğŸ“¸ í‘œì • ì œì¶œí•˜ê³  ì ìˆ˜ ë°›ê¸°</button>
            <div id="emotion-scoreDisplay" class="emotion-display-text">ì ìˆ˜: -</div>
        </div>
        <button onclick="closeFacialModal()" style="position:absolute; top:20px; right:20px; background-color: #555;">X ë‹«ê¸°</button>
    </div>

    <script>
        // --- Unity Loader Script (ê¸°ì¡´ê³¼ ë™ì¼) ---
        var canvas_unity_element = document.querySelector("#unity-canvas"); // ë³€ìˆ˜ëª… ë³€ê²½ (var canvas -> var canvas_unity_element)
        function unityShowBanner(msg, type) {
            var warningBanner = document.querySelector("#unity-warning");
            function updateBannerVisibility() {
                warningBanner.style.display = warningBanner.children.length ? 'block' : 'none';
            }
            var div = document.createElement('div');
            div.innerHTML = msg;
            warningBanner.appendChild(div);
            if (type == 'error') div.style = 'background: red; padding: 10px;';
            else {
                if (type == 'warning') div.style = 'background: yellow; padding: 10px;';
                setTimeout(function() {
                    warningBanner.removeChild(div);
                    updateBannerVisibility();
                }, 5000);
            }
            updateBannerVisibility();
        }

        var loaderUrl = "{{ url_for('static', filename='unity_game_files/Build/towerdefense.loader.js') }}";
        var config = {
            arguments: [],
            dataUrl: "{{ url_for('static', filename='unity_game_files/Build/towerdefense.data') }}",
            frameworkUrl: "{{ url_for('static', filename='unity_game_files/Build/towerdefense.framework.js') }}",
            codeUrl: "{{ url_for('static', filename='unity_game_files/Build/towerdefense.wasm') }}",
            productName: "towerdefense",
            showBanner: unityShowBanner,
            devicePixelRatio: 1,
        };

        if (/iPhone|iPad|iPod|Android/i.test(navigator.userAgent)) {
            var meta = document.createElement('meta');
            meta.name = 'viewport';
            meta.content = 'width=device-width, height=device-height, initial-scale=1.0, user-scalable=no, shrink-to-fit=yes';
            document.getElementsByTagName('head')[0].appendChild(meta);
            document.querySelector("#unity-container").className = "unity-mobile";
            if (canvas_unity_element) canvas_unity_element.className = "unity-mobile"; // ë³€ìˆ˜ëª… ì‚¬ìš©
        }
        document.querySelector("#unity-loading-bar").style.display = "block";

        var script_unity = document.createElement("script");
        script_unity.src = loaderUrl;
        script_unity.onload = () => {
            createUnityInstance(canvas_unity_element, config, (progress) => { // ë³€ìˆ˜ëª… ì‚¬ìš©
                document.querySelector("#unity-progress-bar-full").style.width = 100 * progress + "%";
            }).then((unityInstance) => {
                window.unityGameInstance = unityInstance;
                console.log("Unity Instance Loaded and assigned to window.unityGameInstance!");
                loadAllFacialModels(); 

                document.querySelector("#unity-loading-bar").style.display = "none";
                if (document.querySelector("#unity-fullscreen-button")) {
                    document.querySelector("#unity-fullscreen-button").onclick = () => {
                        unityInstance.SetFullscreen(1);
                    };
                }
            }).catch((message) => {
                alert(message);
            });
        };
        document.body.appendChild(script_unity);

        // ==================================================
        // ğŸ‘‡ ì–¼êµ´ í‰ê°€ ê´€ë ¨ JavaScript ë¡œì§ ğŸ‘‡
        // ==================================================

        let currentActiveFacialMode = null;
        let faceApiModelLoaded_Emotion = false;

        const emotionModeUI = document.getElementById('emotion-mode-ui');
        const emotionReferenceImg = document.getElementById('emotion-referenceImg');
        const emotionVideo = document.getElementById('emotion-video');
        const emotionScoreDisplay = document.getElementById('emotion-scoreDisplay');
        const emotionRefEmotionDisplay = document.getElementById('emotion-refEmotionDisplay');
        const emotionUserEmotionDisplay = document.getElementById('emotion-userEmotionDisplay');
        const emotionCaptureBtn = document.getElementById('emotion-captureBtn');
        const emotionGuideCanvas = document.getElementById('emotion-guideCanvas');

        const emotionImageCount = 50;
        const emotionImageIndices = Array.from({ length: emotionImageCount }, (_, i) => i + 1);
        let currentEmotionReferenceImageNumber = 0;

        async function loadEmotionModels() {
            if (faceApiModelLoaded_Emotion) {
                console.log("Emotion models already loaded.");
                return true; 
            }
            if (typeof faceapi === 'undefined') {
                console.error("face-api.js is not loaded yet!");
                alert("ì–¼êµ´ ì¸ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
                return false;
            }
            try {
                console.log("Loading face-api.js models for emotion mode...");
                const modelPath = '/models';
                await faceapi.nets.tinyFaceDetector.loadFromUri(modelPath);
                await faceapi.nets.faceExpressionNet.loadFromUri(modelPath);
                await faceapi.nets.faceLandmark68Net.loadFromUri(modelPath);
                faceApiModelLoaded_Emotion = true;
                console.log("Emotion mode (face-api.js) models loaded successfully from:", modelPath);
                return true;
            } catch (error) {
                console.error("Error loading face-api.js models from path '" + modelPath + "':", error);
                alert("ì–¼êµ´ ì¸ì‹ ëª¨ë¸(ê°ì •) ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ëª¨ë¸ ê²½ë¡œ ë° ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
                return false;
            }
        }

        async function startVideoForEmotionMode() {
            if (emotionVideo.srcObject && emotionVideo.srcObject.active) {
                console.log("Webcam for emotion mode is already active.");
                if (emotionVideo.paused) {
                    emotionVideo.play().catch(e => console.error("Error restarting paused video:", e));
                }
                return true;
            }
            try {
                console.log("Requesting webcam for emotion mode...");
                const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
                console.log("Webcam stream obtained:", stream);

                if (stream.getTracks().length > 0) {
                    console.log("Webcam stream has tracks:", stream.getTracks());
                } else {
                    console.warn("Webcam stream has NO tracks. This might be an issue.");
                }

                emotionVideo.srcObject = stream;

                emotionVideo.play().then(() => {
                    console.log("emotionVideo.play() initiated successfully via promise.");
                }).catch(err => {
                    console.error("emotionVideo.play() promise failed:", err);
                });

                return new Promise((resolve) => {
                    emotionVideo.onloadedmetadata = () => {
                        console.log("emotionVideo metadata loaded. Client dimensions:", emotionVideo.clientWidth, "x", emotionVideo.clientHeight);
                        if (emotionVideo.clientWidth > 0 && emotionVideo.clientHeight > 0) {
                            // ê°€ì´ë“œ ìº”ë²„ìŠ¤ ê´€ë ¨ ë¡œì§ì€ ShowFacialRecognitionUI_JSì—ì„œ display ì—¬ë¶€ë¥¼ ê²°ì •í•˜ë¯€ë¡œ
                            // ì—¬ê¸°ì„œëŠ” ê·¸ë¦¬ê¸°ë§Œ ë‹´ë‹¹ (ë‹¨, ìº”ë²„ìŠ¤ê°€ display:block ìƒíƒœì—¬ì•¼ ì˜ë¯¸ ìˆìŒ)
                            if (emotionGuideCanvas && emotionGuideCanvas.style.display !== 'none') { 
                                emotionGuideCanvas.width = emotionVideo.clientWidth;
                                emotionGuideCanvas.height = emotionVideo.clientHeight;
                                drawGuideEllipseForEmotion(); 
                            }
                            console.log("Webcam for emotion mode started (guide drawn if canvas visible).");
                            resolve(true);
                        } else {
                            setTimeout(() => {
                                console.log("Retrying to get video dimensions. Client dimensions:", emotionVideo.clientWidth, "x", emotionVideo.clientHeight);
                                if (emotionVideo.clientWidth > 0 && emotionVideo.clientHeight > 0) {
                                    if (emotionGuideCanvas && emotionGuideCanvas.style.display !== 'none') {
                                        emotionGuideCanvas.width = emotionVideo.clientWidth;
                                        emotionGuideCanvas.height = emotionVideo.clientHeight;
                                        drawGuideEllipseForEmotion(); 
                                    }
                                    console.log("Webcam for emotion mode started (after delay, guide drawn if canvas visible).");
                                    resolve(true);
                                } else {
                                    console.error("Emotion video dimensions are still zero after delay.");
                                    alert("ì›¹ìº  í™”ë©´ í¬ê¸°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê±°ë‚˜ ì¹´ë©”ë¼ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
                                    resolve(false);
                                }
                            }, 300); 
                        }
                    };
                    emotionVideo.onerror = (e) => { 
                        console.error("Error event on video element:", e);
                        alert("ì›¹ìº  ë¹„ë””ì˜¤ ìš”ì†Œì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì½˜ì†”ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
                        resolve(false);
                    }
                });
            } catch (err) {
                console.error("Error accessing webcam for emotion mode (getUserMedia failed):", err);
                let alertMessage = "ì›¹ìº (ê°ì •)ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.";
                if (err.name === "NotAllowedError") {
                    alertMessage = "ì›¹ìº (ê°ì •) ì‚¬ìš© ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ë˜ëŠ” ì•„ì´íŒ¨ë“œ ì„¤ì •ì—ì„œ ì¹´ë©”ë¼ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.";
                } else if (err.name === "NotFoundError") {
                    alertMessage = "ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•„ì´íŒ¨ë“œì— ì¹´ë©”ë¼ê°€ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.";
                } else if (err.name === "NotReadableError") {
                    alertMessage = "ì¹´ë©”ë¼ë¥¼ í˜„ì¬ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì•±ì´ ì‚¬ìš© ì¤‘ì´ê±°ë‚˜, ì¼ì‹œì ì¸ í•˜ë“œì›¨ì–´ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•„ì´íŒ¨ë“œë¥¼ ì¬ì‹œë™í•´ë³´ì„¸ìš”.";
                } else if (err.name === "OverconstrainedError") {
                    alertMessage = "ìš”ì²­í•œ ì¡°ê±´ìœ¼ë¡œ ì¹´ë©”ë¼ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê°œë°œì í™•ì¸ í•„ìš”)";
                } else if (err.name === "SecurityError") {
                     alertMessage = "ì¹´ë©”ë¼ ì ‘ê·¼ì´ ë³´ì•ˆìƒì˜ ì´ìœ ë¡œ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì›¹ì‚¬ì´íŠ¸ê°€ HTTPSë¡œ ì ‘ì†ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.";
                } else {
                    alertMessage += ` (ì—ëŸ¬ëª…: ${err.name})`;
                }
                alert(alertMessage);
                return false;
            }
        }

        function drawGuideEllipseForEmotion() {
            if (!emotionGuideCanvas || !emotionVideo.srcObject || emotionVideo.clientWidth === 0 || emotionGuideCanvas.style.display === 'none') return; 
            const ctx = emotionGuideCanvas.getContext("2d");
            ctx.clearRect(0, 0, emotionGuideCanvas.width, emotionGuideCanvas.height);
            ctx.strokeStyle = "rgba(0, 255, 0, 0.6)";
            ctx.lineWidth = 3;
            ctx.beginPath();
            ctx.ellipse(emotionVideo.clientWidth / 2, emotionVideo.clientHeight / 2,
                        emotionVideo.clientWidth * 0.25, emotionVideo.clientHeight * 0.38, 0, 0, 2 * Math.PI);
            ctx.stroke();
        }

        async function setupSingleEmotionExercise() {
            console.log("Setting up single emotion exercise...");
            currentEmotionReferenceImageNumber = emotionImageIndices[Math.floor(Math.random() * emotionImageIndices.length)];

            const imageUrl = `/static/images/e_game/e${currentEmotionReferenceImageNumber}.png`; 
            emotionReferenceImg.src = imageUrl;
            console.log("Attempting to load reference image:", emotionReferenceImg.src);

            emotionRefEmotionDisplay.innerHTML = `ê¸°ì¤€ ê°ì •: - (ì´ë¯¸ì§€ ë¶„ì„ì¤‘...)`;
            emotionUserEmotionDisplay.innerHTML = `ë‹¹ì‹  ê°ì •: -`;
            emotionScoreDisplay.innerHTML = `ì ìˆ˜: -`;

            try {
                await waitForImageLoadForModal(emotionReferenceImg);
                console.log("Reference image for emotion loaded successfully:", emotionReferenceImg.src);

                const refResult = await tryRecognizeReferenceEmotionForModal(true); 
                if (refResult && refResult.expressions) {
                    const refEmotion = getTopEmotion(refResult.expressions);
                    emotionRefEmotionDisplay.innerHTML = `ê¸°ì¤€ ê°ì •: <b>${refEmotion}</b>`;
                    console.log("Reference emotion recognized:", refEmotion);
                } else {
                    emotionRefEmotionDisplay.innerHTML = `ê¸°ì¤€ ê°ì •: (ë¶„ì„ ì‹¤íŒ¨)`;
                    console.warn("Failed to recognize reference emotion (refResult or expressions null).");
                }
            } catch (error) {
                console.error("Failed to load or process reference image in setupSingleEmotionExercise:", error);
                emotionRefEmotionDisplay.innerHTML = `ê¸°ì¤€ ê°ì •: (ì´ë¯¸ì§€ ì˜¤ë¥˜)`;
            }
        }

        // ... (cosineSimilarity, waitForImageLoadForModal, tryRecognizeReferenceEmotionForModal, getTopEmotion, processEmotionExpression - ë³€ê²½ ì—†ìŒ) ...
        function cosineSimilarity(a, b) {
            const dot = a.reduce((sum, val, i) => sum + val * b[i], 0);
            const magA = Math.sqrt(a.reduce((sum, val) => sum + val * val, 0));
            const magB = Math.sqrt(b.reduce((sum, val) => sum + val * val, 0));
            if (magA === 0 || magB === 0) return 0;
            return dot / (magA * magB);
        }

        function waitForImageLoadForModal(imgElement) {
            return new Promise((resolve, reject) => {
                if (imgElement.complete && imgElement.naturalHeight !== 0) {
                    resolve();
                } else {
                    imgElement.onload = () => resolve();
                    imgElement.onerror = () => {
                        console.error("waitForImageLoadForModal: Image load failed for", imgElement.src);
                        reject(new Error("ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: " + imgElement.src));
                    };
                }
            });
        }

        async function tryRecognizeReferenceEmotionForModal(isSetup = false, maxAttempts = 1) {
            if (!faceApiModelLoaded_Emotion) { console.error("Emotion models not loaded for ref check."); return null;}
            for (let attempt = 0; attempt < maxAttempts; attempt++) {
                try {
                    await waitForImageLoadForModal(emotionReferenceImg); 
                    const refResult = await faceapi
                        .detectSingleFace(emotionReferenceImg, new faceapi.TinyFaceDetectorOptions())
                        .withFaceLandmarks()
                        .withFaceExpressions();
                    if (refResult && refResult.expressions) {
                        return refResult;
                    }
                } catch (error) {
                    console.error(`Error in tryRecognizeReferenceEmotionForModal (attempt ${attempt + 1}):`, error);
                }
            }
            console.warn("Failed to detect reference emotion after all attempts.");
            return null;
        }

        const getTopEmotion = exp => Object.entries(exp).sort((a, b) => b[1] - a[1])[0][0];

async function processEmotionExpression() {
                console.log("processEmotionExpression: Function started."); // í•¨ìˆ˜ ì‹œì‘ ë¡œê·¸

                if (!faceApiModelLoaded_Emotion) {
                        alert("ì–¼êµ´ ì¸ì‹ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
                        if(emotionCaptureBtn) emotionCaptureBtn.disabled = false;
                        console.warn("processEmotionExpression: Models not loaded."); // ëª¨ë¸ ë¯¸ë¡œë“œ ë¡œê·¸
                        return;
                }
                if (!emotionVideo.srcObject || emotionVideo.paused || emotionVideo.ended || emotionVideo.readyState < 3) { 
                        alert("ì›¹ìº ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì˜ìƒ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
                        if(emotionCaptureBtn) emotionCaptureBtn.disabled = false;
                        console.warn("processEmotionExpression: Webcam not ready."); // ì›¹ìº  ë¯¸ì¤€ë¹„ ë¡œê·¸
                        return;
                }

                if(emotionCaptureBtn) emotionCaptureBtn.disabled = true;
                emotionScoreDisplay.innerHTML = `ì ìˆ˜: ë¶„ì„ ì¤‘...`;
                console.log("processEmotionExpression: Score display set to 'ë¶„ì„ ì¤‘...'");

                let userDetections;
                try {
                        console.log("processEmotionExpression: Attempting to detect user face...");
                        userDetections = await faceapi.detectSingleFace(emotionVideo, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions();
                } catch (error) {
                        console.error("processEmotionExpression: Error during user face detection:", error);
                        alert("âŒ ì‚¬ìš©ì ì–¼êµ´ ì¸ì‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ! ì½˜ì†”ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
                        emotionUserEmotionDisplay.innerHTML = `ë‹¹ì‹  ê°ì •: (ì˜¤ë¥˜)`;
                        sendScoreToUnityAndHideModal(0); // ì˜¤ë¥˜ ì‹œ 0ì  ì²˜ë¦¬ ë° ëª¨ë‹¬ ë‹«ê¸°
                        return;
                }
                
                if (!userDetections || !userDetections.expressions) {
                        alert("âŒ ì‚¬ìš©ì ì–¼êµ´ í‘œì •ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
                        emotionUserEmotionDisplay.innerHTML = `ë‹¹ì‹  ê°ì •: (ì¸ì‹ ì‹¤íŒ¨)`;
                        console.warn("processEmotionExpression: User face detection failed.");
                        sendScoreToUnityAndHideModal(0);
                        return;
                }
                const userEmotion = getTopEmotion(userDetections.expressions);
                emotionUserEmotionDisplay.innerHTML = `ë‹¹ì‹  ê°ì •: <b>${userEmotion}</b>`;
                console.log("processEmotionExpression: User emotion detected:", userEmotion);

                let refResult;
                try {
                        console.log("processEmotionExpression: Attempting to recognize reference emotion...");
                        refResult = await tryRecognizeReferenceEmotionForModal(false, 1);
                } catch (error) {
                        console.error("processEmotionExpression: Error during reference emotion recognition:", error);
                        alert("âŒ ê¸°ì¤€ ì´ë¯¸ì§€ ì¸ì‹ ì¤‘ ì˜¤ë¥˜ ë°œìƒ! ì½˜ì†”ì„ í™•ì¸í•´ì£¼ì„¸ìš”.");
                        emotionRefEmotionDisplay.innerHTML = `ê¸°ì¤€ ê°ì •: (ì˜¤ë¥˜)`;
                        sendScoreToUnityAndHideModal(0); // ì˜¤ë¥˜ ì‹œ 0ì  ì²˜ë¦¬ ë° ëª¨ë‹¬ ë‹«ê¸°
                        return;
                }

                if (!refResult || !refResult.expressions) {
                        alert("âŒ ê¸°ì¤€ ì´ë¯¸ì§€ì˜ ê°ì •ì„ ì¸ì‹ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
                        emotionRefEmotionDisplay.innerHTML = `ê¸°ì¤€ ê°ì •: (ì¸ì‹ ì‹¤íŒ¨)`;
                        console.warn("processEmotionExpression: Reference emotion recognition failed.");
                        sendScoreToUnityAndHideModal(0);
                        return;
                }
                const refEmotion = getTopEmotion(refResult.expressions);
                emotionRefEmotionDisplay.innerHTML = `ê¸°ì¤€ ê°ì •: <b>${refEmotion}</b>`;
                console.log("processEmotionExpression: Reference emotion recognized:", refEmotion);

                const refVec = Object.values(refResult.expressions);
                const userVec = Object.values(userDetections.expressions);
                const sim = cosineSimilarity(refVec, userVec);
                const calculatedScore = Math.max(0, Math.min(10, Math.round(sim * 10)));
                console.log("processEmotionExpression: Similarity:", sim, "Calculated score:", calculatedScore);

                emotionScoreDisplay.innerHTML = `íšë“ ì ìˆ˜: <b>${calculatedScore} / 10</b>`;
                console.log("processEmotionExpression: Score display updated to:", calculatedScore);
                
                sendScoreToUnityAndHideModal(calculatedScore);
                console.log("processEmotionExpression: Called sendScoreToUnityAndHideModal. Function finished.");
        }

        // ==================================================
        // ğŸ‘‡ ShowFacialRecognitionUI_JS í•¨ìˆ˜: í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ìˆ˜ì •í•©ë‹ˆë‹¤.
        // ==================================================
        async function ShowFacialRecognitionUI_JS(mode) {
            console.log("ShowFacialRecognitionUI_JS called from Unity with mode:", mode);
            currentActiveFacialMode = mode;
            const modal = document.getElementById('facial-recognition-modal');
            const emotionUI = document.getElementById('emotion-mode-ui');

            if (!modal || !emotionUI) { console.error("Modal or UI elements not found!"); return; }

            if (mode === 'emotion_expression') {
                emotionUI.style.display = 'block';
                modal.style.display = 'flex';

                if (!faceApiModelLoaded_Emotion) {
                    const modelsLoaded = await loadEmotionModels();
                    if (!modelsLoaded) {
                        closeFacialModal();
                        return;
                    }
                }
                const videoStarted = await startVideoForEmotionMode();
                if (!videoStarted) { 
                    closeFacialModal();
                    return;
                }

                // â–¼â–¼â–¼â–¼â–¼ í…ŒìŠ¤íŠ¸ 1: ê°€ì´ë“œ ìº”ë²„ìŠ¤ë§Œ ìˆ¨ê¸°ê³ , ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ ì‹¤í–‰ (ë˜ëŠ” ì§€ì—°) â–¼â–¼â–¼â–¼â–¼
                console.log("Test 1: Hiding guide canvas. Other setups will proceed (possibly delayed).");

                if (emotionGuideCanvas) {
                    emotionGuideCanvas.style.display = 'none'; // ê°€ì´ë“œ ìº”ë²„ìŠ¤ ê°•ì œ ìˆ¨ê¹€
                    console.log("emotionGuideCanvas display set to none for Test 1.");
                }

                // setupSingleEmotionExerciseì™€ ë²„íŠ¼ ì„¤ì •ì€ ì›ë˜ëŒ€ë¡œ (ë˜ëŠ” ì´ì „ í…ŒìŠ¤íŠ¸ì²˜ëŸ¼ setTimeoutìœ¼ë¡œ ì§€ì—°)
                // ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ ì›ë˜ëŒ€ë¡œ ë³µì›ëœ ì½”ë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ canvasë§Œ ìˆ¨ê¸´ë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
                // ë§Œì•½ ì´ì „ ë‹¨ê³„ì—ì„œ setTimeoutìœ¼ë¡œ ì§€ì—°ì‹œì¼°ë˜ ì½”ë“œê°€ ì´ ì•ˆì— ìˆë‹¤ë©´ ê·¸ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.
                // ì´ ì½”ë“œëŠ” ì´ì „ ë‹µë³€ì—ì„œ setTimeout ë¶€ë¶„ì„ ì œê±°í•˜ê³  ì›ë˜ëŒ€ë¡œ ë³µì›í•œ ê²ƒì„ ê¸°ì¤€ìœ¼ë¡œ í•©ë‹ˆë‹¤.

                await setupSingleEmotionExercise(); 
                console.log("Finished setupSingleEmotionExercise call (Test 1).");

                if(emotionCaptureBtn) { 
                    emotionCaptureBtn.disabled = false; 
                    emotionCaptureBtn.removeEventListener('click', processEmotionExpression);
                    emotionCaptureBtn.addEventListener('click', processEmotionExpression);
                    console.log("emotionCaptureBtn setup re-enabled (Test 1).");
                }
                // â–²â–²â–²â–²â–² í…ŒìŠ¤íŠ¸ 1 ë â–²â–²â–²â–²â–²

            } else if (mode === 'follow_expression') {
                emotionUI.style.display = 'none';
                alert("'í‘œì • ë”°ë¼í•˜ê¸° ëª¨ë“œ'ëŠ” ì•„ì§ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
                closeFacialModal();
            } else {
                console.error("Unknown facial exercise mode:", mode);
                closeFacialModal();
            }
        }
        // ==================================================
        // ğŸ‘† ShowFacialRecognitionUI_JS í•¨ìˆ˜ ìˆ˜ì • ë ğŸ‘†
        // ==================================================


        function closeFacialModal() {
            console.log("Closing facial modal for mode:", currentActiveFacialMode);
            const modal = document.getElementById('facial-recognition-modal');
            if (modal) {
                modal.style.display = 'none';
            }

            if (currentActiveFacialMode === 'emotion_expression' && emotionVideo.srcObject) {
                emotionVideo.srcObject.getTracks().forEach(track => track.stop());
                emotionVideo.srcObject = null; 
                console.log("Emotion mode webcam stopped.");
                const uiToHide = document.getElementById('emotion-mode-ui');
                if(uiToHide) uiToHide.style.display = 'none';
            }
            // ëª¨ë‹¬ì´ ë‹«í ë•Œ ê°€ì´ë“œ ìº”ë²„ìŠ¤ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ë‹¤ì‹œ ë³´ì´ê²Œ í•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤.
            // ì–´ì°¨í”¼ ëª¨ë‹¬ ìì²´ê°€ display: noneì´ ë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
            // ShowFacialRecognitionUI_JSì—ì„œ ëª¨ë‹¬ì´ ì—´ë¦´ ë•Œ display:blockìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
            // if (emotionGuideCanvas) {
            //      emotionGuideCanvas.style.display = 'block'; 
            // }
            currentActiveFacialMode = null;
        }

        function sendScoreToUnityAndHideModal(score) {
            if (window.unityGameInstance) {
                window.unityGameInstance.SendMessage('CostManagerObject', 'ReceiveFacialScore', score);
                console.log("Score (" + score + ") sent to Unity.");
            } else {
                console.warn("Unity instance (window.unityGameInstance) not found.");
            }

            setTimeout(() => {
                closeFacialModal();
            }, 2000);
        }

        async function loadAllFacialModels() {
            await loadEmotionModels();
        }

        window.addEventListener('DOMContentLoaded', () => {
            console.log("DOM fully loaded. Call loadAllFacialModels() if needed or wait for Unity to load.");
        });
    </script>
</body>
</html>